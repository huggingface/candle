[package]
name = "wgpu-compute-layer"
version.workspace = true
edition.workspace = true

description = "Wgpu Compute Engine for Candle"
repository = "https://github.com/huggingface/candle"
keywords = ["blas", "tensor", "machine-learning"]
categories = ["science"]
license = "MIT OR Apache-2.0"

[dependencies]
wgpu = { workspace = true }
flume = { workspace = true }
bytemuck = { workspace = true }
pollster = { workspace = true }
log = { workspace = true }
rustc-hash = { workspace = true }
num-traits = { workspace = true }
rand = { workspace = true }
thiserror = { workspace = true }

serde_json = { workspace = true, optional = true }
serde = { workspace = true, optional = true }

tracing = { workspace = true, features = ["release_max_level_off"] }
wgpu-compute-layer-macro = { path = "./wgpu-compute-layer-macro" }
zip = { workspace = true, optional = true }


[target.'cfg(target_arch = "wasm32")'.dependencies]
getrandom = { version = "0.3", features = [
    "wasm_js",
] } #needed for cargo clippy --target wasm32-unknown-unknown

[features]
wgpu_debug = ["dep:serde", "dep:serde_json", "dep:zip"]
wgpu_debug_serialize = ["dep:serde", "dep:serde_json"]
default = []
