//! Open Contrastive Language-Image Pre-Training
//!
//! Open Contrastive Language-Image Pre-Training (OpenCLIP) is an architecture trained on
//! pairs of images with related texts.
//!
//! - ğŸ’» [GH Link](https://github.com/mlfoundations/open_clip)
//! - ğŸ“ [Paper](https://arxiv.org/abs/2212.07143)
//!
//! ## Overview
//!
//! ![](https://raw.githubusercontent.com/mlfoundations/open_clip/main/docs/CLIP.png)

pub mod text_model;
