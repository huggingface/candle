#define BLOCK_SIZE 32
#define BIT_SIZE 5

#define D_OFFSET 0
#define QH_OFFSET 2
#define QS_OFFSET 6

#define TS 1
#define WGS 1
#define TID_SIZE 4
//tid0 loads 0-3 and 16-19, (loads 8 value), but the stride for tid1 is 4 (it must load) 4-7 and 20-24
#define STRIDE_WIDTHB 4
#define CUSTOM_QUANTIZED_INDEX(i, base) ((base / 32) * 32) + (base % 32 + i % 6 + (i / 6u) * 16u) % 32
#define SIZE_AREG 12

#pp_begin LOAD_HEADER(data)
let block_starting_byte = block_index * BLOCK_BYTE_SIZE;
let block_qs_byte = block_starting_byte + QS_OFFSET;
let header_data1 = load_u32(data, block_starting_byte / 4u);
let header_data2 = load_u32(data, (block_starting_byte / 4u) + 1u);
let d = half_to_float((header_data1 >> (((block_starting_byte) % 4) * 8)) & 0xFFFF);

let is_even_block = 1u - (block_index & 1u); //0 or 1
let is_even_block_mask = (0u - is_even_block) & 0xFFFFFFFF; // 0 or 0xFFFFFFFF
let hi1 = (header_data1 >> 16u)  & 0xFFFFu;   // bytes 2–3 of header_data1
let lo2 =  (header_data2)        & 0xFFFFu;    // bytes 0–1 of header_data
let qh_even = (hi1 << 16u) | lo2;            // even block rule
let qh_odd  = header_data2;                  // odd block rule

// ----- branch-free select -----
//let qh = (qh_even & is_even_block_mask) | (qh_odd & ~is_even_block_mask);
let base_word   = (block_qs_byte + 3u) / 4u;
let shift_bytes = block_qs_byte & 3u;

#if (QH_OFFSET % 4 == 0) && (BLOCK_BYTE_SIZE % 4 == 0)
    let qh = data[(block_starting_byte + QH_OFFSET) / 4];
#else
    let qh = load_data(data,block_starting_byte+QH_OFFSET,0xFFFF) | (load_data(data,block_starting_byte+QH_OFFSET+2,0xFFFF)) << 16 ;
#endif

#pp_end

#pp_begin LOAD_SINGLE (data, tid)
    let THREADS_PER_BLOCK = BLOCK_SIZE / VALUES_PER_THREAD;
    let loads_per_thread = (VALUES_PER_THREAD / 8u); //we load 8 values (u32) at the same time
    let j = tid * loads_per_thread;
    
    let start = block_qs_byte / 4u + j;

    //naive solution
    //for(var m = 0u; m < VALUES_PER_THREAD;m++){
    //      let x_u8 = load_data(data,block_qs_byte + j * VALUES_PER_THREAD + m,0xFF);
    //      let x0 = x_u8 & 0x0F;
    //      let x1 = x_u8 >> 4;
    //      #define DEFAULT_M_OFFSET 8
    //      CALLBACK(j * VALUES_PER_THREAD + m          , f32(i32(x0) - DEFAULT_M_OFFSET)*d)
    //      CALLBACK(j * VALUES_PER_THREAD + m + 16, f32(i32(x1) - DEFAULT_M_OFFSET)*d)
    // }

    for(var l = 0u; l < loads_per_thread; l += 1u){
        //let shift_bits  = shift_bytes * 8u;
        let out_base = (shift_bytes + j * 4u + l * 4u);
        let word_index = base_word + j + l * loads_per_thread;
        let w = load_u32(data, word_index); //every thread loads only one word
        let is_last_u = (tid + 1u) / THREADS_PER_BLOCK;
        
        let include_header = is_last_u & is_even_block;

        let full_mask = (0u - include_header) & 0xFFFFFFFF;

        let AND_W_VALUE      = 0x0000FFFFu | (~full_mask);
        let AND_HEADER_VALUE = full_mask & 0xFFFF0000u;

        let high = w & AND_W_VALUE;
        let low  = header_data2 & AND_HEADER_VALUE;

        let combined = low | high; //tid0-6 use the complete low part, tid7 uses the high part to complete the last u32
        let x_u32 = combined;
        
        let x12_u8 = x_u32 & 0xFF;
        let x34_u8 = (x_u32 >> 8)  & 0xFF;
        let x56_u8 = (x_u32 >> 16) & 0xFF;
        let x78_u8 = (x_u32 >> 24) & 0xFF;

        #define DEFAULT_M_OFFSET 16
        #definec BLOCK_SIZE_HALF_MINUS_1 (BLOCK_SIZE/2-1)
        let index12 = (out_base + 0) & BLOCK_SIZE_HALF_MINUS_1;
        let index34 = (out_base + 1) & BLOCK_SIZE_HALF_MINUS_1;
        let index56 = (out_base + 2) & BLOCK_SIZE_HALF_MINUS_1;
        let index78 = (out_base + 3) & BLOCK_SIZE_HALF_MINUS_1;

        let x0 = (x12_u8 & 0x0F) | (((qh >> index12) << 4) & 0x10);
        let x1 = (x12_u8 >> 4) | ((qh >> (index12 + 12)) & 0x10);
        let x2 = (x34_u8 & 0x0F) | (((qh >> index34) << 4) & 0x10);
        let x3 = (x34_u8 >> 4) | ((qh >> (index34 + 12)) & 0x10);
        let x4 = (x56_u8 & 0x0F) | (((qh >> index56) << 4) & 0x10);
        let x5 = (x56_u8 >> 4) | ((qh >> (index56 + 12)) & 0x10);
        let x6 = (x78_u8 & 0x0F) | (((qh >> index78) << 4) & 0x10);
        let x7 = (x78_u8 >> 4) | ((qh >> (index78 + 12)) & 0x10);

        CALLBACK(index12, f32(i32(x0) - DEFAULT_M_OFFSET)*d, 0u + is_even_block * 2)
        CALLBACK(index12 + 16, f32(i32(x1) - DEFAULT_M_OFFSET)*d,  6u + is_even_block * 2)
        CALLBACK(index34, f32(i32(x2) - DEFAULT_M_OFFSET)*d, 1u + is_even_block * 2)
        CALLBACK(index34 + 16, f32(i32(x3) - DEFAULT_M_OFFSET)*d, 7u + is_even_block * 2)
        CALLBACK(index56, f32(i32(x4) - DEFAULT_M_OFFSET)*d, 2u + is_even_block * 2u + is_even_block * is_last_u * 6u)
        CALLBACK(index56 + 16, f32(i32(x5) - DEFAULT_M_OFFSET)*d, 8u + is_even_block * 2u - is_even_block * is_last_u * 6u)
        CALLBACK(index78, f32(i32(x6) - DEFAULT_M_OFFSET)*d, 3u + is_even_block * 2u + is_even_block * is_last_u * 6u)
        CALLBACK(index78 + 16, f32(i32(x7) - DEFAULT_M_OFFSET)*d, 9u + is_even_block * 2u - is_even_block * is_last_u * 6u)
    }
#pp_end


#include "quantHelper.pwgsl"

#ifdef SGEMM
#define WIDTHA 4u
#definec WIDTHB VALUES_PER_THREAD 

#include "matmulHelperSgemm.pwgsl"


MATMUL(matmul_sgemm)
#endif

