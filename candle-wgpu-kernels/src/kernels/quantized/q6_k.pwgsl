#define BLOCK_SIZE 256
#define BIT_SIZE 6
#define Q6K

#define  QL_OFFSET 0
#definec QL_SIZE BLOCK_SIZE / 2

#definec QH_OFFSET QL_OFFSET + QL_SIZE
#definec QH_SIZE BLOCK_SIZE / 4

#definec SCALES_OFFSET QH_OFFSET + QH_SIZE
#definec SCALES_SIZE BLOCK_SIZE / 16

#definec D_OFFSET SCALES_OFFSET + SCALES_SIZE
#define D_SIZE 2

#definec BLOCK_BYTE_SIZE QL_SIZE + QH_SIZE + SCALES_SIZE + D_SIZE

#define TS 1
#define WGS 1
#define TID_SIZE 1

#pp_begin LOAD_HEADER(data)
let block_starting_byte = block_index * BLOCK_BYTE_SIZE;
let d = half_to_float(load_data(data,block_starting_byte + D_OFFSET,0xFFFF));
#pp_end

//TODO: the BLOCK_BYTE_SIZE is not divisible by 4, so we cannot do u32 loads for everything in a "simple way", 
// but every odd block has 2 bytes offset at the start.
#pp_begin LOAD_SINGLE (data,tid)
    let THREADS_PER_BLOCK = BLOCK_SIZE / VALUES_PER_THREAD;
    let loads_per_thread = (VALUES_PER_THREAD / 4u); //we load 4 values (u32) at the same time
    let a = tid * loads_per_thread;
    for (var n = 0u; n < BLOCK_SIZE; n += 128u) {
        let idx = n / 128u;
        let sc_offset = block_starting_byte+SCALES_OFFSET + 8u * idx; // let sc = &sc[8 * idx..];
        let ql_offset = block_starting_byte+QL_OFFSET + 64u * idx; // let ql = &ql[64 * idx..];
        let qh_offset = block_starting_byte+QH_OFFSET + 32u * idx; // let qh = &qh[32 * idx..];
        
        var scale0 = f32(load_i8(data,sc_offset,0xFF));
        var scale1 = f32(load_i8(data,sc_offset+2,0xFF));
        var scale2 = f32(load_i8(data,sc_offset+4,0xFF));
        var scale3 = f32(load_i8(data,sc_offset+6,0xFF));
        for (var l = 0u; l < 16u; l += 1u) {
            let ql1 = load_data(data,ql_offset + l,0xFF);
            let ql2 = load_data(data,ql_offset + l + 32u,0xFF);

            let qh1 = load_data(data,qh_offset + l,0xFF);

            let q1 = i32((ql1 & 0xF) | ((qh1 & 3) << 4)) - 32;
            let q2 = i32((ql2 & 0xF) | (((qh1 >> 2) & 3) << 4))- 32;
            let q3 = i32((ql1 >> 4) | (((qh1 >> 4) & 3) << 4)) - 32;
            let q4 = i32((ql2 >> 4) | (((qh1 >> 6) & 3) << 4)) - 32;

            CALLBACK(n + l,      d * scale0 * f32(q1), n + l)
            CALLBACK(n + l + 32, d * scale1 * f32(q2), n + l + 32)
            CALLBACK(n + l + 64, d * scale2 * f32(q3), n + l + 64)
            CALLBACK(n + l + 96, d * scale3 * f32(q4), n + l + 96)
        }

        scale0 = f32(load_i8(data,sc_offset+1,0xFF));
        scale1 = f32(load_i8(data,sc_offset+3,0xFF));
        scale2 = f32(load_i8(data,sc_offset+5,0xFF));
        scale3 = f32(load_i8(data,sc_offset+7,0xFF));
        for (var l = 16u; l < 32u; l += 1u) {
            let ql1 = load_data(data,ql_offset + l,0xFF);
            let ql2 = load_data(data,ql_offset + l + 32u,0xFF);

            let qh1 = load_data(data,qh_offset + l,0xFF);

            let q1 = i32((ql1 & 0xF) | ((qh1 & 3) << 4)) - 32;
            let q2 = i32((ql2 & 0xF) | (((qh1 >> 2) & 3) << 4))- 32;
            let q3 = i32((ql1 >> 4) | (((qh1 >> 4) & 3) << 4)) - 32;
            let q4 = i32((ql2 >> 4) | (((qh1 >> 6) & 3) << 4)) - 32;

            CALLBACK(n + l,      d * scale0 * f32(q1), n + l)
            CALLBACK(n + l + 32, d * scale1 * f32(q2), n + l + 32)
            CALLBACK(n + l + 64, d * scale2 * f32(q3), n + l + 64)
            CALLBACK(n + l + 96, d * scale3 * f32(q4), n + l + 96)
        }
    }
#pp_end

#include "quantHelper.pwgsl"

#ifdef SGEMM
#define WIDTHA 4u
#definec WIDTHB VALUES_PER_THREAD 

#include "matmulHelperSgemm.pwgsl"


MATMUL(matmul_sgemm)
#endif

